{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "from augerino import datasets, models, losses\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from data.generate_data import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp2058/miniconda3/envs/augerino/lib/python3.11/site-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/sp2058/miniconda3/envs/augerino/lib/python3.11/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/sp2058/augerino/experiments/mario-iggy/data/generate_data.py:106: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  train_images = train_images[np.ix_(trainshuffler), ::].squeeze()\n"
     ]
    }
   ],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "savedir = \"./saved-outputs/\"\n",
    "\n",
    "ntrain = 10000\n",
    "ntest = 5000\n",
    "\n",
    "trainloader, testloader = generate_mario_data(ntrain=ntrain, ntest=ntest,\n",
    "                                              batch_size=128, dpath=\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, reg=0.01, epochs=20):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01, weight_decay=0.)\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    logger = []\n",
    "\n",
    "    criterion = losses.unif_aug_loss\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            # print(inputs.shape)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels, model,\n",
    "                            reg=reg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            log = softplus(model.aug.width).tolist()\n",
    "            log += model.aug.width.grad.data.tolist()\n",
    "            log += [loss.item()]\n",
    "            logger.append(log)\n",
    "            \n",
    "    logdf = pd.DataFrame(logger)\n",
    "    logdf.columns = ['width' + str(i) for i in range(6)] + ['grad' + str(i) for i in range(6)] + ['loss']\n",
    "    logdf = logdf.reset_index()\n",
    "    return logdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/home/sp2058/augerino/experiments/mario-iggy/saved-outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.SimpleConv(c=32, num_classes=4)\n",
    "augerino = models.UniformAug()\n",
    "high_model = models.AugAveragedModel(net, augerino,ncopies=1)\n",
    "\n",
    "start_widths = torch.ones(6) * -5.\n",
    "start_widths[2] = -1.\n",
    "high_model.aug.set_width(start_widths)\n",
    "\n",
    "high_logger = trainer(high_model, reg=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(high_model.state_dict(), savedir + \"highreg.pt\")\n",
    "high_logger.to_pickle(savedir + \"high_logger.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.SimpleConv(c=32, num_classes=4)\n",
    "augerino = models.UniformAug()\n",
    "low_model = models.AugAveragedModel(net, augerino,ncopies=1)\n",
    "\n",
    "start_widths = torch.ones(6) * -5.\n",
    "start_widths[2] = -1.\n",
    "\n",
    "low_model.aug.set_width(start_widths)\n",
    "low_logger = trainer(low_model, reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(low_model.state_dict(), savedir + \"lowreg.pt\")\n",
    "low_logger.to_pickle(savedir + \"low_logger.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.SimpleConv(c=32, num_classes=4)\n",
    "augerino = models.UniformAug()\n",
    "mid_model = models.AugAveragedModel(net, augerino,ncopies=1)\n",
    "\n",
    "start_widths = torch.ones(6) * -5.\n",
    "start_widths[2] = -1.\n",
    "\n",
    "mid_model.aug.set_width(start_widths)\n",
    "mid_logger = trainer(mid_model, reg=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(high_model.state_dict(), savedir + \"midreg.pt\")\n",
    "mid_logger.to_pickle(savedir + \"mid_logger.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_logger['lowbd'] = -low_logger['width2']/2.\n",
    "low_logger['upbd'] = low_logger['width2']/2.\n",
    "high_logger['lowbd'] = -high_logger['width2']/2.\n",
    "high_logger['upbd'] = high_logger['width2']/2.\n",
    "mid_logger['lowbd'] = -mid_logger['width2']/2.\n",
    "mid_logger['upbd'] = mid_logger['width2']/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "lwd = 0.\n",
    "\n",
    "def plot_shade(logger, ax, color, label=\"\"):\n",
    "    ax.fill_between(logger.index, logger['lowbd'], logger['upbd'],\n",
    "                    alpha=alpha, color=color,\n",
    "                    linewidth=lwd)\n",
    "    sns.lineplot(x=logger.index, y='lowbd', color=color, data=logger, label=label)\n",
    "    sns.lineplot(x=logger.index, y='upbd', color=color, data=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_pts = [-np.pi/2, -np.pi/4, 0, np.pi/4, np.pi/2]\n",
    "tick_labs = [r\"-$\\pi$/2\", r'-$\\pi$/4', '0', r'$\\pi$/4', r'$\\pi$/2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1, 1, figsize=(8, 4), dpi=100)\n",
    "fs = 14\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "col0 = pal[0]\n",
    "col1 = pal[1]\n",
    "col2 = pal[2]\n",
    "\n",
    "plot_shade(low_logger, ax0, col0, \"Low Reg\")\n",
    "plot_shade(mid_logger, ax0, col1, \"Mid Reg\")\n",
    "plot_shade(high_logger, ax0, col2, \"High Reg\")\n",
    "\n",
    "# ax0.set_title(\"Rotation Distributions\")\n",
    "ax0.set_xlabel(\"Iteration\", fontsize=fs)\n",
    "ax0.set_ylabel(\"Rotation Width\", fontsize=fs)\n",
    "# ax0.set_title(\"CE Losses\")\n",
    "ax0.tick_params(\"both\", labelsize=fs-2)\n",
    "sns.despine()\n",
    "ax0.set_xticks([])\n",
    "ax0.set_yticks(tick_pts)\n",
    "ax0.set_yticklabels(tick_labs)\n",
    "# ax0.set_xlim(0, 500)\n",
    "# ax0.legend()\n",
    "# plt.setp(ax0.get_legend().get_texts(), fontsize=fs-4) # for legend text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
